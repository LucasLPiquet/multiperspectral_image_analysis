# multiperspectral_image_analysis

## Description
Repository created with the purpose of testing and exploring multiperspectral images in order to compare the differences between what the eyes can perceive and what is actually shown in other, invisible, frequencies.

## Objective
The research has already begun, so I'm going to update what has been already done, and what I'm still working at.
The initial problem to be solved was to help the Physics Institute in USP to lessen the amount of time and effort they need to put into taking samples of regions in a specific art piece or document to analyse the chemycal components to it.
To do so, we have access to 16 multispectral sub-images of the image (document/art piece) we want to analyse, and we want to group the pixels of this image according to its behavior when relfected by each of the 16 chosen frequencies.

## Creating a RGB image
The idea, initially, is to group the image according to the visual colouring, so that we can divide the main problem into a simpler one: divide the pixels of one specific color, according to the multispectral images.
We don't have access to the original RGB image, so we need to build it using the informations in each of the 16 frequencies sub-images. To do so, we took a look at the source of the MISHA capturing software, which has implemented exactly what we need.
It uses the CIE 1931 colour-matching functions to recreate a RGB image.
I tried using other methods for creating the RGB image, for example, I tried searching for which frequencies were the ones responsible for the red, green and blue, but the image wasn't as saturated and as bright. The other idea was to use linear regression to find out the weights of each frequency, but, again, despite being significantly better than the last idea, it was still not as satisfactory as the one using the CIE functions.

## Grouping the pixels visually
After that, we can use the RGB image to group the regions with similar colour. To accomplish this, we used k-means clustering (I will, eventually, try other clusterings algorithms), and trained the clustering in two ways: 
- The first one was to train it to find each cluster center in an colourful image
- The second one was training it on the RGB image that we are analysing.

The intuitition behing the first method was to have the clustering to learn how to distinguish between the colours, and group it. Since we know which cluster is associated with each colour, the result is pretty interpretable. However, given that many images, mainly documents, aren't really that colourful, most of the clusters are sparse, and, sometimes, separate pixels that are similar, while grouping pixels taht are visually different.
The intuition behind the second method is to have a clustering algorithm that is adapted to the image we wish to group, in order to have a more representative grouping. Despite that, the groupings are less interpretable, because the clusterings rely completly on the image we are analysing, and doesn't have a direct connection with each color.
We're still analysing which direction to go.

## Grouping the pixels multispectrally
After that, we are going to test grouping algorithms, such as TSNE, k-means... to group the pixels of each group generated by the clustered image in terms of their multispectral behavior. We've already built a prototype of a TSNE algorithm to group the pixels

# Updates (02/27/26)
## Grouping the pixels visually
I've tried a number of clustering algorithms in order to choose the one with the best performance. In most of them, I've used the LAB color space instead of the RGB one, because it reflects better the human perception of colors, and it results in . The ones tested and their respective performance are listed bellow:
- K-Means: Perhaps the most intuitive one, that was the first algorithm tested. On top of its simplicity, what makes the algorithm interesting is its speed, being one of the quickest ways to cluster big images. Despite its simplicity, this algorithm actually had an okay performance.
- HDBSCAN: Often used in actual real-life problems of segmenting colors, this was one of the most promising algorithms. However, it has proven itself to be incredibly slow, being O(nÂ²), which makes it unviable for the research, given the high number of big images. The speed was considerably slow even with the usage of GPU, so the HDBSCAN had to be scrapped.
- Median-cut + PCA: This combination of algorithms is widely used in real-life problems, such as color quantization for not completely rendered images. Perhaps this algorithm would do really well on paintings, landscapes and colorful images, but when it comes to written documents (which we are currently working with), the low contrast of colors make this algorithm bad at separating the colors, since it prioritizes too much th different stains, and not so much the actual paints used in the document.
- GMM: GMM is similar to K-Means in terms of speed, but it uses an stocastic component to its algorithm, which makes it less sensitive to the stains on the paper and more acurate on prioritizing the actual painting and not the paper.

After testing each algorithm in different images, I've realized that GMM was the one with the best performance in general. However, none of the results actually dealt well with the parts of the document that were just plain paper. Given the dating of the documents, they had many stains, which where often confused as paint. Also, having a low number of clusters made the clusters to diverse, and increasing the number of clusters often separated more the paper than the actual colors of the paints (again, because of the stains).

So right now, I've decided to work on separating paper and paint, in order to only apply the clustering algorithm on the actual paint, and not the paper.
